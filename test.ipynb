{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 09:17:22.257702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-01 09:17:22.257797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-01 09:17:22.259584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-01 09:17:22.271728: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.15.0\n",
      "12.0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if len(gpus) > 1:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "print(tf.__version__)\n",
    "print(tf.sysconfig.get_build_info()[\"cuda_version\"])\n",
    "print(tf.sysconfig.get_build_info()[\"cudnn_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.logits_ph Tensor(\"deepspeech/logits:0\", shape=(None, None, 29), dtype=float32)\n",
      "self.input_node_ph Tensor(\"deepspeech/input_node:0\", shape=(None, None, 494), dtype=float32)\n",
      "self.input_lengths_ph Tensor(\"deepspeech/input_lengths:0\", shape=(None,), dtype=int32)\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:af:00.0, compute capability: 8.9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 09:17:40.859826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12107 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:af:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import resampy\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# tf.compat.v1.config.optimizer.set_jit(True)\n",
    "\n",
    "class DeepSpeech():\n",
    "    def __init__(self,model_path):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            with tf.io.gfile.GFile(model_path, \"rb\") as f:\n",
    "                graph_def = tf.compat.v1.GraphDef()\n",
    "                graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name=\"deepspeech\")\n",
    "            self.logits_ph = self.graph.get_tensor_by_name(\"deepspeech/logits:0\")\n",
    "            print(\"self.logits_ph\", self.logits_ph)\n",
    "            self.input_node_ph = self.graph.get_tensor_by_name(\"deepspeech/input_node:0\")\n",
    "            print(\"self.input_node_ph\", self.input_node_ph)\n",
    "            self.input_lengths_ph = self.graph.get_tensor_by_name(\"deepspeech/input_lengths:0\")\n",
    "            print(\"self.input_lengths_ph\", self.input_lengths_ph)\n",
    "            config = tf.compat.v1.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "            config.graph_options.optimizer_options.global_jit_level = tf.compat.v1.OptimizerOptions.ON_1\n",
    "            config.log_device_placement = True\n",
    "            self.session = tf.compat.v1.Session(config=config)\n",
    "        self.target_sample_rate = 16000\n",
    "\n",
    "    def _prepare_deepspeech_net(self,deepspeech_pb_path):\n",
    "        tf.compat.v1.disable_eager_execution()  # Bật chế độ tương thích TF1.x\n",
    "        with tf.io.gfile.GFile(deepspeech_pb_path, \"rb\") as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        tf.import_graph_def(graph_def, name=\"deepspeech\")\n",
    "        logits_ph = graph.get_tensor_by_name(\"deepspeech/logits:0\")\n",
    "        input_node_ph = graph.get_tensor_by_name(\"deepspeech/input_node:0\")\n",
    "        input_lengths_ph = graph.get_tensor_by_name(\"deepspeech/input_lengths:0\")\n",
    "\n",
    "        return graph, logits_ph, input_node_ph, input_lengths_ph\n",
    "\n",
    "    def conv_audio_to_deepspeech_input_vector(self,audio,\n",
    "                                              sample_rate,\n",
    "                                              num_cepstrum,\n",
    "                                              num_context):\n",
    "        # Get mfcc coefficients:\n",
    "        features = mfcc(\n",
    "            signal=audio,\n",
    "            samplerate=sample_rate,\n",
    "            numcep=num_cepstrum)\n",
    "\n",
    "        # We only keep every second feature (BiRNN stride = 2):\n",
    "        features = features[::2]\n",
    "\n",
    "        # One stride per time step in the input:\n",
    "        num_strides = len(features)\n",
    "\n",
    "        # Add empty initial and final contexts:\n",
    "        empty_context = np.zeros((num_context, num_cepstrum), dtype=features.dtype)\n",
    "        features = np.concatenate((empty_context, features, empty_context))\n",
    "\n",
    "        # Create a view into the array with overlapping strides of size\n",
    "        # numcontext (past) + 1 (present) + numcontext (future):\n",
    "        window_size = 2 * num_context + 1\n",
    "        train_inputs = np.lib.stride_tricks.as_strided(\n",
    "            features,\n",
    "            shape=(num_strides, window_size, num_cepstrum),\n",
    "            strides=(features.strides[0],\n",
    "                     features.strides[0], features.strides[1]),\n",
    "            writeable=False)\n",
    "\n",
    "        # Flatten the second and third dimensions:\n",
    "        train_inputs = np.reshape(train_inputs, [num_strides, -1])\n",
    "\n",
    "        train_inputs = np.copy(train_inputs)\n",
    "        train_inputs = (train_inputs - np.mean(train_inputs)) / \\\n",
    "                       np.std(train_inputs)\n",
    "\n",
    "        return train_inputs\n",
    "\n",
    "    def compute_audio_feature(self, audio_path):\n",
    "        start_time = time.time()\n",
    "        audio_sample_rate, audio = wavfile.read(audio_path)\n",
    "        print(audio_sample_rate)\n",
    "        if audio.ndim != 1:\n",
    "            warnings.warn(\n",
    "                \"Audio has multiple channels, the first channel is used\")\n",
    "            audio = audio[:, 0]\n",
    "        if audio_sample_rate != self.target_sample_rate:\n",
    "            resampled_audio = resampy.resample(\n",
    "                x=audio.astype(float),\n",
    "                sr_orig=audio_sample_rate,\n",
    "                sr_new=self.target_sample_rate)\n",
    "        else:\n",
    "            # resampled_audio = audio.astype(np.float)\n",
    "            resampled_audio = audio.astype(float)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to resample audio: {end_time - start_time} seconds\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        input_vector = self.conv_audio_to_deepspeech_input_vector(\n",
    "            audio=resampled_audio.astype(np.int16),\n",
    "            sample_rate=self.target_sample_rate,\n",
    "            num_cepstrum=26,\n",
    "            num_context=9)\n",
    "        end_time = time.time()\n",
    "        print(\"input_vector\", input_vector.shape)\n",
    "        print(f\"Time taken to convert audio to input vector: {end_time - start_time} seconds\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        network_output = self.session.run(\n",
    "                self.logits_ph,\n",
    "                feed_dict={\n",
    "                    self.input_node_ph: input_vector[np.newaxis, ...],\n",
    "                    self.input_lengths_ph: [input_vector.shape[0]]\n",
    "                })\n",
    "        print(\"network_output\", network_output.shape)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to run network: {end_time - start_time} seconds\")\n",
    "        ds_features = network_output[::2,0,:]\n",
    "        print(\"ds_features\", ds_features.shape)\n",
    "        return ds_features\n",
    "\n",
    "DSModel = DeepSpeech('./asserts/output_graph.pb')\n",
    "\n",
    "# input_vector.shape = (410, 494) = (num_strides(=410), window_size(=2*num_context+1=2*8+1=19) * num_cepstrum(=26) )\n",
    "# network_output.shape = (410, 1, 29) = (num_strides(=410), batch_size(=1), num_classes(=29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "Time taken to resample audio: 0.14072537422180176 seconds\n",
      "input_vector (410, 494)\n",
      "Time taken to convert audio to input vector: 0.022240877151489258 seconds\n",
      "network_output (410, 1, 29)\n",
      "Time taken to run network: 0.20188570022583008 seconds\n",
      "ds_features (205, 29)\n",
      "ds_feature (205, 29)\n"
     ]
    }
   ],
   "source": [
    "ds_feature = DSModel.compute_audio_feature('output_audio.wav')\n",
    "print(\"ds_feature\", ds_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import resampy\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "class DeepSpeech():\n",
    "    def __init__(self, model_path):\n",
    "        # TensorFlow 2.x không cần phải sử dụng tf.Graph() như TensorFlow 1.x\n",
    "        # Hãy tải mô hình trực tiếp bằng cách sử dụng tf.saved_model.load()\n",
    "        self.model = tf.saved_model.load(model_path)\n",
    "        self.target_sample_rate = 16000\n",
    "        \n",
    "        # Lấy các tensor từ mô hình\n",
    "        self.input_node_ph = self.model.signatures['serving_default'].inputs[0]  # Xác định tên của input tensor\n",
    "        self.logits_ph = self.model.signatures['serving_default'].outputs[0]  # Xác định tên của output tensor\n",
    "        print(f\"Input node: {self.input_node_ph}, Logits node: {self.logits_ph}\")\n",
    "    \n",
    "    def conv_audio_to_deepspeech_input_vector(self, audio, sample_rate, num_cepstrum, num_context):\n",
    "        # Extract mfcc features\n",
    "        features = mfcc(signal=audio, samplerate=sample_rate, numcep=num_cepstrum)\n",
    "        features = features[::2]  # Keep every second feature\n",
    "        num_strides = len(features)\n",
    "\n",
    "        # Add empty initial and final contexts\n",
    "        empty_context = np.zeros((num_context, num_cepstrum), dtype=features.dtype)\n",
    "        features = np.concatenate((empty_context, features, empty_context))\n",
    "\n",
    "        window_size = 2 * num_context + 1\n",
    "        train_inputs = np.lib.stride_tricks.as_strided(features, shape=(num_strides, window_size, num_cepstrum), \n",
    "                                                       strides=(features.strides[0], features.strides[0], features.strides[1]), \n",
    "                                                       writeable=False)\n",
    "        train_inputs = np.reshape(train_inputs, [num_strides, -1])\n",
    "        train_inputs = np.copy(train_inputs)\n",
    "        train_inputs = (train_inputs - np.mean(train_inputs)) / np.std(train_inputs)\n",
    "\n",
    "        return train_inputs\n",
    "\n",
    "    def compute_audio_feature(self, audio_path):\n",
    "        start_time = time.time()\n",
    "        audio_sample_rate, audio = wavfile.read(audio_path)\n",
    "        print(audio_sample_rate)\n",
    "        if audio.ndim != 1:\n",
    "            warnings.warn(\"Audio has multiple channels, the first channel is used\")\n",
    "            audio = audio[:, 0]\n",
    "        if audio_sample_rate != self.target_sample_rate:\n",
    "            resampled_audio = resampy.resample(x=audio.astype(float), sr_orig=audio_sample_rate, sr_new=self.target_sample_rate)\n",
    "        else:\n",
    "            resampled_audio = audio.astype(float)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to resample audio: {end_time - start_time} seconds\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        input_vector = self.conv_audio_to_deepspeech_input_vector(audio=resampled_audio.astype(np.int16), \n",
    "                                                                 sample_rate=self.target_sample_rate, \n",
    "                                                                 num_cepstrum=26, \n",
    "                                                                 num_context=9)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to convert audio to input vector: {end_time - start_time} seconds\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # TensorFlow 2.x không cần phải dùng session, chỉ cần gọi mô hình với input\n",
    "        input_tensor = tf.convert_to_tensor(input_vector[np.newaxis, ...], dtype=tf.float32)\n",
    "        logits = self.model(input_tensor)\n",
    "        \n",
    "        print(f\"Logits shape: {logits.shape}\")\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to run network: {end_time - start_time} seconds\")\n",
    "        \n",
    "        ds_features = logits[::2, 0, :]\n",
    "        print(f\"ds_features shape: {ds_features.shape}\")\n",
    "        \n",
    "        return ds_features\n",
    "\n",
    "# Đường dẫn tới mô hình .pb đã được lưu\n",
    "DSModel = DeepSpeech('./asserts/output_graph.pb')\n",
    "\n",
    "# Lưu ý rằng chúng ta cần chuyển mô hình của bạn sang định dạng TensorFlow SavedModel\n",
    "# Nếu mô hình của bạn chưa được lưu dưới định dạng này, bạn có thể chuyển đổi bằng cách sử dụng:\n",
    "# model.save('saved_model/my_model') trước khi chạy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation: input_node\n",
      "    Tensor name: input_node:0\n",
      "Operation: input_lengths\n",
      "    Tensor name: input_lengths:0\n",
      "Operation: ToInt64\n",
      "    Tensor name: ToInt64:0\n",
      "Operation: Shape\n",
      "    Tensor name: Shape:0\n",
      "Operation: transpose/perm\n",
      "    Tensor name: transpose/perm:0\n",
      "Operation: transpose\n",
      "    Tensor name: transpose:0\n",
      "Operation: Reshape/shape\n",
      "    Tensor name: Reshape/shape:0\n",
      "Operation: Reshape\n",
      "    Tensor name: Reshape:0\n",
      "Operation: b1\n",
      "    Tensor name: b1:0\n",
      "Operation: b1/read\n",
      "    Tensor name: b1/read:0\n",
      "Operation: h1\n",
      "    Tensor name: h1:0\n",
      "Operation: h1/read\n",
      "    Tensor name: h1/read:0\n",
      "Operation: MatMul\n",
      "    Tensor name: MatMul:0\n",
      "Operation: Add\n",
      "    Tensor name: Add:0\n",
      "Operation: Relu\n",
      "    Tensor name: Relu:0\n",
      "Operation: Minimum/y\n",
      "    Tensor name: Minimum/y:0\n",
      "Operation: Minimum\n",
      "    Tensor name: Minimum:0\n",
      "Operation: b2\n",
      "    Tensor name: b2:0\n",
      "Operation: b2/read\n",
      "    Tensor name: b2/read:0\n",
      "Operation: h2\n",
      "    Tensor name: h2:0\n",
      "Operation: h2/read\n",
      "    Tensor name: h2/read:0\n",
      "Operation: MatMul_1\n",
      "    Tensor name: MatMul_1:0\n",
      "Operation: Add_1\n",
      "    Tensor name: Add_1:0\n",
      "Operation: Relu_1\n",
      "    Tensor name: Relu_1:0\n",
      "Operation: Minimum_1/y\n",
      "    Tensor name: Minimum_1/y:0\n",
      "Operation: Minimum_1\n",
      "    Tensor name: Minimum_1:0\n",
      "Operation: b3\n",
      "    Tensor name: b3:0\n",
      "Operation: b3/read\n",
      "    Tensor name: b3/read:0\n",
      "Operation: h3\n",
      "    Tensor name: h3:0\n",
      "Operation: h3/read\n",
      "    Tensor name: h3/read:0\n",
      "Operation: MatMul_2\n",
      "    Tensor name: MatMul_2:0\n",
      "Operation: Add_2\n",
      "    Tensor name: Add_2:0\n",
      "Operation: Relu_2\n",
      "    Tensor name: Relu_2:0\n",
      "Operation: Minimum_2/y\n",
      "    Tensor name: Minimum_2/y:0\n",
      "Operation: Minimum_2\n",
      "    Tensor name: Minimum_2:0\n",
      "Operation: strided_slice/stack\n",
      "    Tensor name: strided_slice/stack:0\n",
      "Operation: strided_slice/stack_1\n",
      "    Tensor name: strided_slice/stack_1:0\n",
      "Operation: strided_slice/stack_2\n",
      "    Tensor name: strided_slice/stack_2:0\n",
      "Operation: strided_slice\n",
      "    Tensor name: strided_slice:0\n",
      "Operation: Reshape_1/shape/0\n",
      "    Tensor name: Reshape_1/shape/0:0\n",
      "Operation: Reshape_1/shape/2\n",
      "    Tensor name: Reshape_1/shape/2:0\n",
      "Operation: Reshape_1/shape\n",
      "    Tensor name: Reshape_1/shape:0\n",
      "Operation: Reshape_1\n",
      "    Tensor name: Reshape_1:0\n",
      "Operation: bidirectional_rnn/fw/ToInt32\n",
      "    Tensor name: bidirectional_rnn/fw/ToInt32:0\n",
      "Operation: bidirectional_rnn/fw/sequence_length\n",
      "    Tensor name: bidirectional_rnn/fw/sequence_length:0\n",
      "Operation: bidirectional_rnn/fw/fw/Shape\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Shape:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice/stack\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice/stack:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice/stack_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice/stack_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice/stack_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice/stack_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims/dim\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims/dim:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat/axis\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat/axis:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros/Const\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros/Const:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2/dim\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2/dim:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const:0\n",
      "Operation: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/Shape_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Shape_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/stack\n",
      "    Tensor name: bidirectional_rnn/fw/fw/stack:0\n",
      "Operation: bidirectional_rnn/fw/fw/Equal\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Equal:0\n",
      "Operation: bidirectional_rnn/fw/fw/Const\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Const:0\n",
      "Operation: bidirectional_rnn/fw/fw/All\n",
      "    Tensor name: bidirectional_rnn/fw/fw/All:0\n",
      "Operation: bidirectional_rnn/fw/fw/Assert/Assert/data_0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Assert/Assert/data_0:0\n",
      "Operation: bidirectional_rnn/fw/fw/Assert/Assert/data_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Assert/Assert/data_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/Assert/Assert\n",
      "Operation: bidirectional_rnn/fw/fw/CheckSeqLen\n",
      "    Tensor name: bidirectional_rnn/fw/fw/CheckSeqLen:0\n",
      "Operation: bidirectional_rnn/fw/fw/Shape_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Shape_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_1/stack\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_1/stack:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_1/stack_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_1/stack_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_1/stack_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_1/stack_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/Shape_3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Shape_3:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_2/stack\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_2/stack:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_2/stack_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_2/stack_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_2/stack_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_2/stack_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/strided_slice_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/strided_slice_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/ExpandDims/dim\n",
      "    Tensor name: bidirectional_rnn/fw/fw/ExpandDims/dim:0\n",
      "Operation: bidirectional_rnn/fw/fw/ExpandDims\n",
      "    Tensor name: bidirectional_rnn/fw/fw/ExpandDims:0\n",
      "Operation: bidirectional_rnn/fw/fw/Const_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/Const_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/concat/axis\n",
      "    Tensor name: bidirectional_rnn/fw/fw/concat/axis:0\n",
      "Operation: bidirectional_rnn/fw/fw/concat\n",
      "    Tensor name: bidirectional_rnn/fw/fw/concat:0\n",
      "Operation: bidirectional_rnn/fw/fw/zeros/Const\n",
      "    Tensor name: bidirectional_rnn/fw/fw/zeros/Const:0\n",
      "Operation: bidirectional_rnn/fw/fw/zeros\n",
      "    Tensor name: bidirectional_rnn/fw/fw/zeros:0\n",
      "Operation: bidirectional_rnn/fw/fw/time\n",
      "    Tensor name: bidirectional_rnn/fw/fw/time:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArray\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArray:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArray:1\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArray_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArray_1:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArray_1:1\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/range\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/range:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Enter_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Enter_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Enter_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Enter_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Enter_3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Enter_3:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Merge\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Merge_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge_1:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge_1:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Merge_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge_2:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge_2:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Merge_3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge_3:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Merge_3:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Less/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Less/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Less\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Less:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/LoopCond\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/LoopCond:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Switch\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Switch_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch_1:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch_1:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Switch_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch_2:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch_2:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Switch_3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch_3:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Switch_3:1\n",
      "Operation: bidirectional_rnn/fw/fw/while/Identity\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Identity:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Identity_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Identity_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Identity_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Identity_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Identity_3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Identity_3:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/TensorArrayReadV3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/TensorArrayReadV3:0\n",
      "Operation: bidirectional_rnn/fw/basic_lstm_cell/kernel\n",
      "    Tensor name: bidirectional_rnn/fw/basic_lstm_cell/kernel:0\n",
      "Operation: bidirectional_rnn/fw/basic_lstm_cell/kernel/read\n",
      "    Tensor name: bidirectional_rnn/fw/basic_lstm_cell/kernel/read:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/concat/axis\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/concat/axis:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/concat\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/concat:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/MatMul/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/MatMul/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/MatMul\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/MatMul:0\n",
      "Operation: bidirectional_rnn/fw/basic_lstm_cell/bias\n",
      "    Tensor name: bidirectional_rnn/fw/basic_lstm_cell/bias:0\n",
      "Operation: bidirectional_rnn/fw/basic_lstm_cell/bias/read\n",
      "    Tensor name: bidirectional_rnn/fw/basic_lstm_cell/bias/read:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/BiasAdd/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/BiasAdd/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/BiasAdd\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/basic_lstm_cell/BiasAdd:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split/split_dim\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split/split_dim:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split:0\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split:1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split:2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/split:3\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/add/y\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/add/y:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/add\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/add:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Sigmoid\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Sigmoid:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/mul\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/mul:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Sigmoid_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Sigmoid_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Tanh\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Tanh:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/mul_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/mul_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/add_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/add_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Tanh_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Tanh_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Sigmoid_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/Sigmoid_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/mul_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/fw/basic_lstm_cell/mul_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/GreaterEqual/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/GreaterEqual/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/GreaterEqual\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/GreaterEqual:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Select/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Select/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Select\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Select:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/GreaterEqual_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/GreaterEqual_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Select_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Select_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/GreaterEqual_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/GreaterEqual_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Select_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Select_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/add/y\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/add/y:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/add\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/add:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/NextIteration\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/NextIteration:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/NextIteration_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/NextIteration_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/NextIteration_2\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/NextIteration_2:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/NextIteration_3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/NextIteration_3:0\n",
      "Operation: bidirectional_rnn/fw/fw/while/Exit_1\n",
      "    Tensor name: bidirectional_rnn/fw/fw/while/Exit_1:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayStack/range/start\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayStack/range/start:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayStack/range/delta\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayStack/range/delta:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayStack/range\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayStack/range:0\n",
      "Operation: bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3\n",
      "    Tensor name: bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0\n",
      "Operation: bidirectional_rnn/bw/ReverseSequence\n",
      "    Tensor name: bidirectional_rnn/bw/ReverseSequence:0\n",
      "Operation: bidirectional_rnn/bw/ToInt32\n",
      "    Tensor name: bidirectional_rnn/bw/ToInt32:0\n",
      "Operation: bidirectional_rnn/bw/sequence_length\n",
      "    Tensor name: bidirectional_rnn/bw/sequence_length:0\n",
      "Operation: bidirectional_rnn/bw/bw/Shape\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Shape:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice/stack\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice/stack:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice/stack_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice/stack_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice/stack_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice/stack_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims/dim\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims/dim:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat/axis\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat/axis:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros/Const\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros/Const:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2/dim\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2/dim:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/Const_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/concat_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const:0\n",
      "Operation: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/Shape_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Shape_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/stack\n",
      "    Tensor name: bidirectional_rnn/bw/bw/stack:0\n",
      "Operation: bidirectional_rnn/bw/bw/Equal\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Equal:0\n",
      "Operation: bidirectional_rnn/bw/bw/Const\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Const:0\n",
      "Operation: bidirectional_rnn/bw/bw/All\n",
      "    Tensor name: bidirectional_rnn/bw/bw/All:0\n",
      "Operation: bidirectional_rnn/bw/bw/Assert/Assert/data_0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Assert/Assert/data_0:0\n",
      "Operation: bidirectional_rnn/bw/bw/Assert/Assert/data_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Assert/Assert/data_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/Assert/Assert\n",
      "Operation: bidirectional_rnn/bw/bw/CheckSeqLen\n",
      "    Tensor name: bidirectional_rnn/bw/bw/CheckSeqLen:0\n",
      "Operation: bidirectional_rnn/bw/bw/Shape_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Shape_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_1/stack\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_1/stack:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_1/stack_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_1/stack_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_1/stack_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_1/stack_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/Shape_3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Shape_3:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_2/stack\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_2/stack:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_2/stack_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_2/stack_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_2/stack_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_2/stack_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/strided_slice_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/strided_slice_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/ExpandDims/dim\n",
      "    Tensor name: bidirectional_rnn/bw/bw/ExpandDims/dim:0\n",
      "Operation: bidirectional_rnn/bw/bw/ExpandDims\n",
      "    Tensor name: bidirectional_rnn/bw/bw/ExpandDims:0\n",
      "Operation: bidirectional_rnn/bw/bw/Const_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/Const_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/concat/axis\n",
      "    Tensor name: bidirectional_rnn/bw/bw/concat/axis:0\n",
      "Operation: bidirectional_rnn/bw/bw/concat\n",
      "    Tensor name: bidirectional_rnn/bw/bw/concat:0\n",
      "Operation: bidirectional_rnn/bw/bw/zeros/Const\n",
      "    Tensor name: bidirectional_rnn/bw/bw/zeros/Const:0\n",
      "Operation: bidirectional_rnn/bw/bw/zeros\n",
      "    Tensor name: bidirectional_rnn/bw/bw/zeros:0\n",
      "Operation: bidirectional_rnn/bw/bw/time\n",
      "    Tensor name: bidirectional_rnn/bw/bw/time:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArray\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArray:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArray:1\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArray_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArray_1:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArray_1:1\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/range\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/range:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Enter_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Enter_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Enter_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Enter_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Enter_3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Enter_3:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Merge\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Merge_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge_1:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge_1:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Merge_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge_2:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge_2:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Merge_3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge_3:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Merge_3:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Less/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Less/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Less\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Less:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/LoopCond\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/LoopCond:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Switch\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Switch_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch_1:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch_1:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Switch_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch_2:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch_2:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Switch_3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch_3:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Switch_3:1\n",
      "Operation: bidirectional_rnn/bw/bw/while/Identity\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Identity:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Identity_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Identity_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Identity_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Identity_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Identity_3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Identity_3:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/TensorArrayReadV3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/TensorArrayReadV3:0\n",
      "Operation: bidirectional_rnn/bw/basic_lstm_cell/kernel\n",
      "    Tensor name: bidirectional_rnn/bw/basic_lstm_cell/kernel:0\n",
      "Operation: bidirectional_rnn/bw/basic_lstm_cell/kernel/read\n",
      "    Tensor name: bidirectional_rnn/bw/basic_lstm_cell/kernel/read:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/concat/axis\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/concat/axis:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/concat\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/concat:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/MatMul/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/MatMul/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/MatMul\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/MatMul:0\n",
      "Operation: bidirectional_rnn/bw/basic_lstm_cell/bias\n",
      "    Tensor name: bidirectional_rnn/bw/basic_lstm_cell/bias:0\n",
      "Operation: bidirectional_rnn/bw/basic_lstm_cell/bias/read\n",
      "    Tensor name: bidirectional_rnn/bw/basic_lstm_cell/bias/read:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/BiasAdd/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/BiasAdd/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/BiasAdd\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/basic_lstm_cell/BiasAdd:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split/split_dim\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split/split_dim:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split:0\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split:1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split:2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/split:3\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/add/y\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/add/y:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/add\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/add:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Sigmoid\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Sigmoid:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/mul\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/mul:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Sigmoid_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Sigmoid_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Tanh\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Tanh:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/mul_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/mul_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/add_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/add_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Tanh_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Tanh_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Sigmoid_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/Sigmoid_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/mul_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/bw/basic_lstm_cell/mul_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/GreaterEqual/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/GreaterEqual/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/GreaterEqual\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/GreaterEqual:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Select/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Select/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Select\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Select:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/GreaterEqual_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/GreaterEqual_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Select_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Select_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/GreaterEqual_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/GreaterEqual_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Select_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Select_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/add/y\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/add/y:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/add\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/add:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/NextIteration\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/NextIteration:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/NextIteration_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/NextIteration_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/NextIteration_2\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/NextIteration_2:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/NextIteration_3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/NextIteration_3:0\n",
      "Operation: bidirectional_rnn/bw/bw/while/Exit_1\n",
      "    Tensor name: bidirectional_rnn/bw/bw/while/Exit_1:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayStack/range/start\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayStack/range/start:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayStack/range/delta\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayStack/range/delta:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayStack/range\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayStack/range:0\n",
      "Operation: bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3\n",
      "    Tensor name: bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3:0\n",
      "Operation: ReverseSequence\n",
      "    Tensor name: ReverseSequence:0\n",
      "Operation: concat/axis\n",
      "    Tensor name: concat/axis:0\n",
      "Operation: concat\n",
      "    Tensor name: concat:0\n",
      "Operation: Reshape_2/shape\n",
      "    Tensor name: Reshape_2/shape:0\n",
      "Operation: Reshape_2\n",
      "    Tensor name: Reshape_2:0\n",
      "Operation: b5\n",
      "    Tensor name: b5:0\n",
      "Operation: b5/read\n",
      "    Tensor name: b5/read:0\n",
      "Operation: h5\n",
      "    Tensor name: h5:0\n",
      "Operation: h5/read\n",
      "    Tensor name: h5/read:0\n",
      "Operation: MatMul_3\n",
      "    Tensor name: MatMul_3:0\n",
      "Operation: Add_3\n",
      "    Tensor name: Add_3:0\n",
      "Operation: Relu_3\n",
      "    Tensor name: Relu_3:0\n",
      "Operation: Minimum_3/y\n",
      "    Tensor name: Minimum_3/y:0\n",
      "Operation: Minimum_3\n",
      "    Tensor name: Minimum_3:0\n",
      "Operation: b6\n",
      "    Tensor name: b6:0\n",
      "Operation: b6/read\n",
      "    Tensor name: b6/read:0\n",
      "Operation: h6\n",
      "    Tensor name: h6:0\n",
      "Operation: h6/read\n",
      "    Tensor name: h6/read:0\n",
      "Operation: MatMul_4\n",
      "    Tensor name: MatMul_4:0\n",
      "Operation: Add_4\n",
      "    Tensor name: Add_4:0\n",
      "Operation: strided_slice_1/stack\n",
      "    Tensor name: strided_slice_1/stack:0\n",
      "Operation: strided_slice_1/stack_1\n",
      "    Tensor name: strided_slice_1/stack_1:0\n",
      "Operation: strided_slice_1/stack_2\n",
      "    Tensor name: strided_slice_1/stack_2:0\n",
      "Operation: strided_slice_1\n",
      "    Tensor name: strided_slice_1:0\n",
      "Operation: logits/shape/0\n",
      "    Tensor name: logits/shape/0:0\n",
      "Operation: logits/shape/2\n",
      "    Tensor name: logits/shape/2:0\n",
      "Operation: logits/shape\n",
      "    Tensor name: logits/shape:0\n",
      "Operation: logits\n",
      "    Tensor name: logits:0\n",
      "Operation: CTCBeamSearchDecoder\n",
      "    Tensor name: CTCBeamSearchDecoder:0\n",
      "    Tensor name: CTCBeamSearchDecoder:1\n",
      "    Tensor name: CTCBeamSearchDecoder:2\n",
      "    Tensor name: CTCBeamSearchDecoder:3\n",
      "Operation: SparseToDense/default_value\n",
      "    Tensor name: SparseToDense/default_value:0\n",
      "Operation: SparseToDense\n",
      "    Tensor name: SparseToDense:0\n",
      "Operation: output_node\n",
      "    Tensor name: output_node:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tải mô hình .pb đã lưu trước đó\n",
    "def load_pb_model(pb_path):\n",
    "    # Tải graph từ file .pb\n",
    "    with tf.io.gfile.GFile(pb_path, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    \n",
    "    # Tạo một graph mới và import graph_def vào graph đó\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# Hàm để kiểm tra các tên tensor trong mô hình\n",
    "def check_tensor_names(pb_path):\n",
    "    graph = load_pb_model(pb_path)\n",
    "\n",
    "    # Duyệt qua tất cả các node và in ra tên tensor\n",
    "    for op in graph.get_operations():\n",
    "        print(f\"Operation: {op.name}\")\n",
    "        for output in op.outputs:\n",
    "            print(f\"    Tensor name: {output.name}\")\n",
    "\n",
    "# kiểm tra tên tensor trong mô hình\n",
    "pb_model_path = './asserts/output_graph.pb'\n",
    "check_tensor_names(pb_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo lớp mô hình có thể theo dõi (Trackable)\n",
    "class DeepSpeechModel(tf.Module):\n",
    "    def __init__(self, graph):\n",
    "        super().__init__()\n",
    "        self.graph = graph\n",
    "        self.input_node = graph.get_tensor_by_name(\"input_node:0\")  # Thay đúng tên tensor\n",
    "        self.logits_node = graph.get_tensor_by_name(\"logits:0\")  # Thay đúng tên tensor\n",
    "        self.input_lengths_node = graph.get_tensor_by_name(\"input_lengths:0\")  # Thay đúng tên tensor\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 494], dtype=tf.float32)])  # Điều chỉnh shape cho phù hợp\n",
    "    def __call__(self, input_vector):\n",
    "        # Mô phỏng quá trình chạy mô hình\n",
    "        with tf.compat.v1.Session(graph=self.graph) as session:\n",
    "            network_output = session.run(\n",
    "                self.logits_node,\n",
    "                feed_dict={self.input_node: input_vector[np.newaxis, ...],\n",
    "                           self.input_lengths_node: [input_vector.shape[0]]}\n",
    "            )\n",
    "        return network_output\n",
    "\n",
    "# Chuyển đổi mô hình .pb thành SavedModel\n",
    "def convert_pb_to_savedmodel(pb_path, saved_model_path):\n",
    "    graph = load_pb_model(pb_path)\n",
    "    model = DeepSpeechModel(graph)\n",
    "\n",
    "    # Lưu mô hình dưới dạng SavedModel\n",
    "    tf.saved_model.save(model, saved_model_path)\n",
    "    print(f\"Model saved to {saved_model_path}\")\n",
    "\n",
    "# Chuyển đổi mô hình .pb thành SavedModel\n",
    "pb_model_path = './asserts/output_graph.pb'\n",
    "saved_model_path = './saved_model/deepspeech_model'\n",
    "convert_pb_to_savedmodel(pb_model_path, saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crop_radius(video_size,landmark_data_clip,random_scale = None):\n",
    "    '''\n",
    "    judge if crop face and compute crop radius\n",
    "    '''\n",
    "    video_w, video_h = video_size[0], video_size[1]\n",
    "    landmark_max_clip = np.max(landmark_data_clip, axis=1)\n",
    "    if random_scale is None:\n",
    "        random_scale = random.random() / 10 + 1.05\n",
    "    else:\n",
    "        random_scale = random_scale\n",
    "\n",
    "    radius_h = (landmark_max_clip[:,1] - landmark_data_clip[:,29, 1]) * random_scale\n",
    "    radius_w = (landmark_data_clip[:,54, 0] - landmark_data_clip[:,48, 0]) * random_scale\n",
    "\n",
    "    radius_clip = np.max(np.stack([radius_h, radius_w],1),1) // 2\n",
    "    radius_max = np.max(radius_clip)\n",
    "    # radius_max = (np.int(radius_max/4) + 1 ) * 4\n",
    "\n",
    "    radius_max = (int(radius_max/4) + 1 ) * 4\n",
    "    \n",
    "    radius_max_1_4 = radius_max//4\n",
    "    clip_min_h = landmark_data_clip[:, 29, 1] - radius_max\n",
    "    clip_max_h = landmark_data_clip[:, 29, 1] + radius_max * 2  + radius_max_1_4\n",
    "    clip_min_w = landmark_data_clip[:, 33, 0] - radius_max - radius_max_1_4\n",
    "    clip_max_w = landmark_data_clip[:, 33, 0] + radius_max + radius_max_1_4\n",
    "    if min(clip_min_h.tolist() + clip_min_w.tolist()) < 0:\n",
    "        print(\"1\")\n",
    "        return False,radius_max\n",
    "    elif max(clip_max_h.tolist()) > video_h:\n",
    "        print(\"2\")\n",
    "        return False,radius_max\n",
    "    elif max(clip_max_w.tolist()) > video_w:\n",
    "        print(\"3\")\n",
    "        return False,radius_max\n",
    "    elif max(radius_clip) > min(radius_clip) * 1.5:\n",
    "        print(\"4\")\n",
    "        return False, radius_max\n",
    "    else:\n",
    "        return True,radius_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_compute_crop_radius(video_size, landmark_data_clip, random_scale=1.05):\n",
    "    '''\n",
    "    Batch processing version of crop radius calculation\n",
    "    '''\n",
    "    video_w, video_h = video_size[0], video_size[1]\n",
    "    \n",
    "    # Calculate max landmarks for each frame in each window\n",
    "    landmark_max_clip = np.max(landmark_data_clip, axis=2)  # Shape: (batch, window_size, 2)\n",
    "    \n",
    "    # Calculate radius components\n",
    "    radius_h = (landmark_max_clip[:, :, 1] - landmark_data_clip[:, :, 29, 1]) * random_scale\n",
    "    radius_w = (landmark_data_clip[:, :, 54, 0] - landmark_data_clip[:, :, 48, 0]) * random_scale\n",
    "    \n",
    "    # Stack and find max radius for each frame\n",
    "    radius_clip = np.max(np.stack([radius_h, radius_w], axis=2), axis=2) // 2  # Shape: (batch, window_size)\n",
    "    \n",
    "    # Find max radius for each window\n",
    "    radius_max = np.max(radius_clip, axis=1)  # Shape: (batch,)\n",
    "    radius_max = (radius_max // 4 + 1) * 4  # Ensure divisible by 4\n",
    "    \n",
    "    radius_max_1_4 = radius_max // 4\n",
    "    \n",
    "    # Calculate crop boundaries\n",
    "    clip_min_h = landmark_data_clip[:, :, 29, 1] - radius_max[:, np.newaxis]\n",
    "    clip_max_h = landmark_data_clip[:, :, 29, 1] + 2 * radius_max[:, np.newaxis] + radius_max_1_4[:, np.newaxis]\n",
    "    clip_min_w = landmark_data_clip[:, :, 33, 0] - radius_max[:, np.newaxis] - radius_max_1_4[:, np.newaxis]\n",
    "    clip_max_w = landmark_data_clip[:, :, 33, 0] + radius_max[:, np.newaxis] + radius_max_1_4[:, np.newaxis]\n",
    "    \n",
    "    # Check validity for each window\n",
    "    valid = (\n",
    "        (np.all(clip_min_h >= 0, axis=1)) &\n",
    "        (np.all(clip_max_h <= video_h, axis=1)) &\n",
    "        (np.all(clip_min_w >= 0, axis=1)) &\n",
    "        (np.all(clip_max_w <= video_w, axis=1)) &\n",
    "        (np.max(radius_clip, axis=1) <= 1.5 * np.min(radius_clip, axis=1))\n",
    "    )\n",
    "    \n",
    "    return valid, radius_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Original compute_crop_radius: False 72\n",
      "Batch compute_crop_radius:    False 72.0\n"
     ]
    }
   ],
   "source": [
    "# Giả định đầu vào\n",
    "frame_h, frame_w = 256, 256\n",
    "video_size = (frame_w, frame_h)\n",
    "resize_w, resize_h = 96, 96\n",
    "\n",
    "# Tạo dữ liệu giả cho landmark: (10 frames, 68 landmarks, 2)\n",
    "N = 10\n",
    "landmarks = np.random.randint(50, 200, size=(N, 68, 2)).astype(np.int32)\n",
    "video_frames = [np.random.randint(0, 255, (frame_h, frame_w, 3), dtype=np.uint8) for _ in range(N)]\n",
    "\n",
    "# Tạo batch landmarks: (1 batch, 5 frames, 68 landmarks, 2)\n",
    "clip = landmarks[2:7]\n",
    "batch_clip = clip[np.newaxis, ...]\n",
    "\n",
    "\n",
    "# -------- GỌI 2 PHIÊN BẢN HÀM compute_crop_radius --------\n",
    "# Gốc\n",
    "flag_ref, radius_ref = compute_crop_radius(video_size, clip, random_scale=1.05)\n",
    "print(\"Original compute_crop_radius:\", flag_ref, radius_ref)\n",
    "\n",
    "# Batch\n",
    "flag_batch, radius_batch = batch_compute_crop_radius(video_size, batch_clip, random_scale=1.05)\n",
    "print(\"Batch compute_crop_radius:   \", flag_batch[0], radius_batch[0])\n",
    "\n",
    "assert flag_ref == flag_batch[0], \"Flag mismatch\"\n",
    "assert abs(radius_ref - radius_batch[0]) <= 4, f\"Radius mismatch: {radius_ref} vs {radius_batch[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize_face(img, landmarks, crop_radius, resize_w, resize_h):\n",
    "    crop_radius_1_4 = crop_radius // 4\n",
    "    cropped = img[\n",
    "        landmarks[29, 1] - crop_radius:landmarks[29, 1] + 2 * crop_radius + crop_radius_1_4,\n",
    "        landmarks[33, 0] - crop_radius - crop_radius_1_4:landmarks[33, 0] + crop_radius + crop_radius_1_4,\n",
    "        :\n",
    "    ]\n",
    "    original_size = (cropped.shape[1], cropped.shape[0])\n",
    "    return cv2.resize(cropped, (resize_w, resize_h)), original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_crop_and_resize(frames, landmarks, radius_list, resize_w, resize_h):\n",
    "    batch_output = []\n",
    "    original_sizes = []\n",
    "    \n",
    "    for frame, landmark, radius in zip(frames, landmarks, radius_list):\n",
    "        try:\n",
    "            # Ensure radius is integer\n",
    "            radius = int(round(radius))\n",
    "            crop_radius_1_4 = radius // 4\n",
    "            \n",
    "            # Calculate coordinates and ensure they are integers\n",
    "            y_start = int(round(landmark[29, 1] - radius))\n",
    "            y_end = int(round(landmark[29, 1] + 2 * radius + crop_radius_1_4))\n",
    "            x_start = int(round(landmark[33, 0] - radius - crop_radius_1_4))\n",
    "            x_end = int(round(landmark[33, 0] + radius + crop_radius_1_4))\n",
    "            \n",
    "            # Validate coordinates\n",
    "            h, w = frame.shape[:2]\n",
    "            y_start = max(0, y_start)\n",
    "            y_end = min(h, y_end)\n",
    "            x_start = max(0, x_start)\n",
    "            x_end = min(w, x_end)\n",
    "            \n",
    "            # Perform cropping\n",
    "            cropped = frame[y_start:y_end, x_start:x_end, :]\n",
    "            original_size = (cropped.shape[1], cropped.shape[0])\n",
    "            \n",
    "            if cropped.size > 0:\n",
    "                resized = cv2.resize(cropped, (resize_w, resize_h))\n",
    "                batch_output.append(resized)\n",
    "                original_sizes.append(original_size)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid crop region\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Crop error: {e}, using fallback\")\n",
    "            fallback = np.zeros((resize_h, resize_w, 3), dtype=np.uint8)\n",
    "            batch_output.append(fallback)\n",
    "            original_sizes.append((resize_w, resize_h))\n",
    "    \n",
    "    return np.array(batch_output), original_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,1):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: (180, 234)\n",
      "Batch size: (180, 234)\n",
      "Cropped image shape: (96, 96, 3)\n",
      "Batch cropped image shape: (96, 96, 3)\n",
      "Max pixel diff: 0\n",
      "✅ Hai phiên bản hoạt động tương đương logic.\n"
     ]
    }
   ],
   "source": [
    "# Giả định đầu vào\n",
    "frame_h, frame_w = 256, 256\n",
    "video_size = (frame_w, frame_h)\n",
    "resize_w, resize_h = 96, 96\n",
    "\n",
    "# Tạo dữ liệu giả cho landmark: (10 frames, 68 landmarks, 2)\n",
    "N = 10\n",
    "landmarks = np.random.randint(50, 200, size=(N, 68, 2)).astype(np.int32)\n",
    "video_frames = [np.random.randint(0, 255, (frame_h, frame_w, 3), dtype=np.uint8) for _ in range(N)]\n",
    "\n",
    "# -------- GỌI 2 PHIÊN BẢN HÀM crop_and_resize --------\n",
    "frame_idx = 3\n",
    "frame = video_frames[frame_idx]\n",
    "lm = landmarks[frame_idx]\n",
    "\n",
    "crop1, size1 = crop_and_resize_face(frame, lm, radius_ref, resize_w, resize_h)\n",
    "crop2_batch, size2_list = batch_crop_and_resize([frame], [lm], [radius_batch[0]], resize_w, resize_h)\n",
    "crop2 = crop2_batch[0]\n",
    "size2 = size2_list[0]\n",
    "\n",
    "# So sánh size\n",
    "print(\"Original size:\", size1)\n",
    "print(\"Batch size:\", size2)\n",
    "assert size1 == size2, f\"Original size mismatch: {size1} vs {size2}\"\n",
    "\n",
    "# So sánh nội dung ảnh\n",
    "print(\"Cropped image shape:\", crop1.shape)\n",
    "print(\"Batch cropped image shape:\", crop2.shape)\n",
    "diff = np.abs(crop1.astype(np.int32) - crop2.astype(np.int32))\n",
    "max_diff = np.max(diff)\n",
    "print(\"Max pixel diff:\", max_diff)\n",
    "\n",
    "assert max_diff < 10, \"Cropped image content mismatch\"\n",
    "\n",
    "print(\"✅ Hai phiên bản hoạt động tương đương logic.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
